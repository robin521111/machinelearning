# KL散度-相对熵
$$
D(p||q)=H(p,q)-H(p)=\sum_{i}^{} p(i)log\frac{p(i)}{q(i)}
$$

相对熵可以衡量两个随机分布之间的距离，当两个随机分布相同时，它们的相对熵为零，当两个随机分布的差别增大时，它们的相对熵也会增大。所以相对熵（KL散度）可以用于比较文本的相似度，先统计出词的频率，然后计算L散度就行了。

# 交叉熵
$$
H(p,q)=-\sum_{i}^{} p(i)log[{q(i)}]
$$ 



# 互信息I(X,Y)
$$
I(X,Y)=D(p_{X,Y}(x,y)||{p_X (x)p_Y (y)})
$$

ICA算法是以最小化互信息为目标的，也就是使得获得变量之间分布不相关。
